{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "passo1) aqui são importadas todas as bibliotecas e definidos todos os modelos que serão utilizados, além disso, manualmente aqui são indicados os paths do video que deverá passar pelo processo definido no script. \n",
    "- instance_dir = diretório da instância... usado como espaço de armazenamento para os folders, arrays e csv's resultantes do processo\n",
    "- instance_id = identificador unico da instância (aqui pode ser definido manualmente, mas é prudente que seja o mesmo nome da instância e que nomes de instancia não se repitam)\n",
    "- group_size = indica qual o numero de frames a serem extraídas do video (aleatoriamente uma vez que esta sendo usado o comando \"get_rando_frame_group\")\n",
    "- vidpath = path do video de onde os frames devem ser extraídos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from keras import applications\n",
    "from tools import evectools as evt\n",
    "import pandas as pd\n",
    "from keras import applications\n",
    "\n",
    "\n",
    "############################This section contains all information necessary previous to the execution of the script#################################################################\n",
    "df = pd.DataFrame()\n",
    "instance_dir = 'C:/Documents/Projects_IC/creativision_nyu/UrbanCreativision/evec_scan/instances/test2'\n",
    "vid_file = 'video2.mp4'\n",
    "instance_id = 'test2'\n",
    "group_size = 6\n",
    "vidpath = 'C:/Documents/Projects_IC/creativision_nyu/UrbanCreativision/evec_scan/instances/test2/video2.mp4' \n",
    "description_models = ['moondream', 'llava-llama3'] #'moondream', 'llava-llama3'\n",
    "description_embedding_models = {\"model\":['mxbai-embed-large'], \"model_origin\":['ollama']} #{\"model\":['mxbai-embed-large', \"ViT-B/32\"], \"model_origin\":['ollama', \"clip\"]} #'mxbai-embed-large','nomic-embed-text', 'all-minilm' from ollama\n",
    "image_embedding_models = {'model':[applications.VGG16, \"ViT-B/32\"], 'model_origin':['keras', 'clip']} #applications.VGG16, applications.DenseNet121\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "passo2) esta próxima seção utiliza ferramentas definidas em evectools.py para extrair o grupo de frames e gerar uma coluna numa dataframe com todas as frames extraídas. No processo, usa \"save_group\" para gerar um folder onde cada frame é salva com seu respectivo nome e numero de identificação. Os paths dessas frames são so valores salvos no dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file exists:  True\n",
      "{'streams': [{'index': 0, 'codec_name': 'h264', 'codec_long_name': 'H.264 / AVC / MPEG-4 AVC / MPEG-4 part 10', 'profile': 'High', 'codec_type': 'video', 'codec_tag_string': 'avc1', 'codec_tag': '0x31637661', 'width': 1920, 'height': 1080, 'coded_width': 1920, 'coded_height': 1080, 'closed_captions': 0, 'film_grain': 0, 'has_b_frames': 0, 'pix_fmt': 'yuvj420p', 'level': 40, 'color_range': 'pc', 'color_space': 'bt470bg', 'color_transfer': 'smpte170m', 'color_primaries': 'bt470bg', 'chroma_location': 'left', 'field_order': 'progressive', 'refs': 1, 'is_avc': 'true', 'nal_length_size': '4', 'id': '0x1', 'r_frame_rate': '30/1', 'avg_frame_rate': '1113840000/37118533', 'time_base': '1/90000', 'start_pts': 0, 'start_time': '0.000000', 'duration_ts': 74237066, 'duration': '824.856289', 'bit_rate': '20006092', 'bits_per_raw_sample': '8', 'nb_frames': '24752', 'extradata_size': 35, 'disposition': {'default': 1, 'dub': 0, 'original': 0, 'comment': 0, 'lyrics': 0, 'karaoke': 0, 'forced': 0, 'hearing_impaired': 0, 'visual_impaired': 0, 'clean_effects': 0, 'attached_pic': 0, 'timed_thumbnails': 0, 'non_diegetic': 0, 'captions': 0, 'descriptions': 0, 'metadata': 0, 'dependent': 0, 'still_image': 0, 'multilayer': 0}, 'tags': {'creation_time': '2024-07-11T17:17:52.000000Z', 'language': 'eng', 'handler_name': 'VideoHandle', 'vendor_id': '[0][0][0][0]'}}, {'index': 1, 'codec_name': 'aac', 'codec_long_name': 'AAC (Advanced Audio Coding)', 'profile': 'LC', 'codec_type': 'audio', 'codec_tag_string': 'mp4a', 'codec_tag': '0x6134706d', 'sample_fmt': 'fltp', 'sample_rate': '48000', 'channels': 2, 'channel_layout': 'stereo', 'bits_per_sample': 0, 'initial_padding': 0, 'id': '0x2', 'r_frame_rate': '0/0', 'avg_frame_rate': '0/0', 'time_base': '1/48000', 'start_pts': 658, 'start_time': '0.013708', 'duration_ts': 39593251, 'duration': '824.859396', 'bit_rate': '155998', 'nb_frames': '38665', 'extradata_size': 2, 'disposition': {'default': 1, 'dub': 0, 'original': 0, 'comment': 0, 'lyrics': 0, 'karaoke': 0, 'forced': 0, 'hearing_impaired': 0, 'visual_impaired': 0, 'clean_effects': 0, 'attached_pic': 0, 'timed_thumbnails': 0, 'non_diegetic': 0, 'captions': 0, 'descriptions': 0, 'metadata': 0, 'dependent': 0, 'still_image': 0, 'multilayer': 0}, 'tags': {'creation_time': '2024-07-11T17:17:52.000000Z', 'language': 'eng', 'handler_name': 'SoundHandle', 'vendor_id': '[0][0][0][0]'}}], 'format': {'filename': 'C:/Documents/Projects_IC/creativision_nyu/UrbanCreativision/evec_scan/instances/test2/video2.mp4', 'nb_streams': 2, 'nb_programs': 0, 'nb_stream_groups': 0, 'format_name': 'mov,mp4,m4a,3gp,3g2,mj2', 'format_long_name': 'QuickTime / MOV', 'start_time': '0.000000', 'duration': '824.873104', 'size': '2079153285', 'bit_rate': '20164587', 'probe_score': 100, 'tags': {'major_brand': 'mp42', 'minor_version': '0', 'compatible_brands': 'isommp42', 'creation_time': '2024-07-11T17:17:52.000000Z', 'com.android.version': '14', 'com.android.manufacturer': 'motorola', 'com.android.model': 'motorola edge 30 neo'}}}\n",
      "files were succesfully saved\n"
     ]
    }
   ],
   "source": [
    "############################This section organizes a small group of frames from the video being analyzed###########################################################################\n",
    "video_instance = evt.FrameExtractor(vidpath=vidpath)\n",
    "frame_group = video_instance.get_random_frame_group(size=group_size)\n",
    "frame_group_instance = video_instance.FrameGroup(frame_extractor=video_instance, group_set=frame_group)\n",
    "frames_output_path = os.path.join(instance_dir, 'frames')\n",
    "frame_path_list = frame_group_instance.save_group(output_dir=frames_output_path, group_name=instance_id)\n",
    "df['frame_path'] = frame_path_list\n",
    "df.index = list(range(len(frame_path_list)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "passo3) aqui são geradas as descrições de cada frame. A lógica utilizada é: Em ordem, para cada frame no dataframe, um primeiro modelo irá gerar a descrição. Na sequência, ele irá salvar essa descrição em uma nova coluna no dataframe, tal que, devido a ordem com que as descrições são geradas, alinhará cada frame com sua respectiva descrição feita por esse modelo. Na sequência um próximo modelo irá gerar as descrições de cada frame e gerar uma nova coluna. O nome da coluna é o nome do modelo usado. No final o dataframe resultante será salvo em um csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################This section gets the descriptions for every frame in the previous group model by model###########################################################################\n",
    "description_columns = []\n",
    "for desc_model in description_models: \n",
    "    descriptions_per_model = []\n",
    "    for frame_path in df['frame_path']:\n",
    "        descriptor = evt.ImgDescriptor(model=desc_model,frame_path=frame_path)\n",
    "        description = descriptor.get_description()\n",
    "        descriptions_per_model.append(description)\n",
    "    df[f'{desc_model}_desc'] = descriptions_per_model\n",
    "    description_columns.append(f'{desc_model}_desc')\n",
    "df_output_path = os.path.join(instance_dir, 'instance_data.csv')\n",
    "df.to_csv(df_output_path, index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "segue o dataframe resultante do passo anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frame_path</th>\n",
       "      <th>moondream_desc</th>\n",
       "      <th>llava-llama3_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:/Documents/Projects_IC/creativision_nyu/Urba...</td>\n",
       "      <td>\\nThe image shows a bus stop on the side of a ...</td>\n",
       "      <td>The image captures a vibrant scene from a stre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:/Documents/Projects_IC/creativision_nyu/Urba...</td>\n",
       "      <td>\\nThe image shows a bus stop on the side of a ...</td>\n",
       "      <td>The image captures a serene urban scene. Domin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:/Documents/Projects_IC/creativision_nyu/Urba...</td>\n",
       "      <td>\\nThe image shows a bus stop on the side of a ...</td>\n",
       "      <td>The image captures a tranquil scene at the ent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:/Documents/Projects_IC/creativision_nyu/Urba...</td>\n",
       "      <td>\\nThe image shows a bus stop on the side of a ...</td>\n",
       "      <td>The image captures a serene urban scene. Domin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:/Documents/Projects_IC/creativision_nyu/Urba...</td>\n",
       "      <td>\\nThe image shows a bus stop on the side of a ...</td>\n",
       "      <td>The image captures a tranquil scene in an urba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>C:/Documents/Projects_IC/creativision_nyu/Urba...</td>\n",
       "      <td>\\nThe image shows a bus stop on the side of a ...</td>\n",
       "      <td>The image captures a scene at the entrance of ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          frame_path  \\\n",
       "0  C:/Documents/Projects_IC/creativision_nyu/Urba...   \n",
       "1  C:/Documents/Projects_IC/creativision_nyu/Urba...   \n",
       "2  C:/Documents/Projects_IC/creativision_nyu/Urba...   \n",
       "3  C:/Documents/Projects_IC/creativision_nyu/Urba...   \n",
       "4  C:/Documents/Projects_IC/creativision_nyu/Urba...   \n",
       "5  C:/Documents/Projects_IC/creativision_nyu/Urba...   \n",
       "\n",
       "                                      moondream_desc  \\\n",
       "0  \\nThe image shows a bus stop on the side of a ...   \n",
       "1  \\nThe image shows a bus stop on the side of a ...   \n",
       "2  \\nThe image shows a bus stop on the side of a ...   \n",
       "3  \\nThe image shows a bus stop on the side of a ...   \n",
       "4  \\nThe image shows a bus stop on the side of a ...   \n",
       "5  \\nThe image shows a bus stop on the side of a ...   \n",
       "\n",
       "                                   llava-llama3_desc  \n",
       "0  The image captures a vibrant scene from a stre...  \n",
       "1  The image captures a serene urban scene. Domin...  \n",
       "2  The image captures a tranquil scene at the ent...  \n",
       "3  The image captures a serene urban scene. Domin...  \n",
       "4  The image captures a tranquil scene in an urba...  \n",
       "5  The image captures a scene at the entrance of ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instance_data = pd.read_csv('C:/Documents/Projects_IC/creativision_nyu/UrbanCreativision/evec_scan/instances/test1/instance_data.csv')\n",
    "instance_data.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "passo4) usando as colunas de descrição do dataframe a próxima etapa consiste em, para cada uma dessas colunas, gerar um folder de ouput dentro de um outro folder chamado desc_evecs (de description embedding vectors). Esse folder terá o nome do modelo de descrição a partir do qual a descrição sob analise foi gerada. Dentro desse folder, será criado um numpy array .npy com o nome do modelo que gerou os embeddings. Nesse .npy estrão em ordem os vetores de embedding de cada frame do dataframe gerado anteriormente. Isso é feito para cada coluna de descrição e por cada modelo de embedding, tal que um folder desc_evecs/moondream_desc pode possuir multiplos .npy, como msbai-embed-large.npy entre outros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observação: problema encontrado ao usar CLIP para fazer embedding das descrições -> esta retornando runtime error. Talvez seja necessário truncar texto para resolver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################This section gets the embedding vector of each description model by model#########################################################################\n",
    "for dir in description_columns:\n",
    "    description_evec_output_dir = os.path.join(instance_dir, 'desc_evecs', dir)\n",
    "    os.makedirs(description_evec_output_dir)\n",
    "    for text_evec_model, model_origin in zip(description_embedding_models['model'],description_embedding_models['model_origin']):\n",
    "        description_evec_arr_per_model_per_desc_model = np.empty(group_size, dtype=object)\n",
    "        i = 0\n",
    "        for description in df[dir]:\n",
    "            text_evec_scanner = evt.TextEvecScanner(model=text_evec_model, text=description, model_origin=model_origin)\n",
    "            text_evec = text_evec_scanner.get_evec()\n",
    "            description_evec_arr_per_model_per_desc_model[i]=text_evec\n",
    "            i += 1\n",
    "        output_path_desc_evec = os.path.join(description_evec_output_dir,f'{str(text_evec_model).replace('/','')}.npy')\n",
    "        np.save(file=output_path_desc_evec, arr=description_evec_arr_per_model_per_desc_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "passo5) para cada modelo de embedding de imagem, são gerados os vetores de embedding de cada frame e colocados dentro do .npy em ordem como no dataframe. Cada .npy tem o nome do modelo que o gerou e se encontra dentro do folder image_evecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the new models list is [<Functional name=vgg16, built=True>]\n",
      "models that will be used have indexes: [0]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step\n"
     ]
    }
   ],
   "source": [
    "#############################This section gets the embedding vector for each frame model by model##########################################################################\n",
    "img_evecs_output_dir = os.path.join(instance_dir, 'img_evecs')\n",
    "os.makedirs(img_evecs_output_dir)\n",
    "for image_evec_model, model_origin in zip(image_embedding_models['model'],image_embedding_models['model_origin']):\n",
    "    image_evec_arr_per_model_per_img_model = np.empty(group_size, dtype=object)\n",
    "    img_evec_scanner = evt.ImgEVecScanner()\n",
    "    if model_origin.lower() == \"keras\":\n",
    "        img_evec_scanner.add_model(Keras_applications_model=image_evec_model)\n",
    "    for frame_path in df['frame_path']:\n",
    "        i = 0\n",
    "        if model_origin.lower() == \"keras\":\n",
    "            res_dict = img_evec_scanner.get_models_evecs(frame_path=frame_path, lin_method='GAP')\n",
    "        elif model_origin.lower() == \"clip\":\n",
    "            res_dict = img_evec_scanner.get_clip_evec(model=image_evec_model, frame_path=frame_path)\n",
    "        for name, evec in zip(res_dict['model_name'],res_dict['embedding_vector']):\n",
    "            output_path_img_evec = os.path.join(img_evecs_output_dir,f'{str(name).replace('/','')}.npy')\n",
    "            image_evec_arr_per_model_per_img_model[i] = evec[0]\n",
    "            i += 1\n",
    "    np.save(file=output_path_img_evec, arr=image_evec_arr_per_model_per_img_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "segue o exemplo de um dos arrays contendo os vetores de embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        1.08919563e+01, 0.00000000e+00, 0.00000000e+00, 1.23310356e+01,\n",
      "        0.00000000e+00, 3.64590049e-01, 0.00000000e+00, 0.00000000e+00,\n",
      "        4.00650978e+00, 0.00000000e+00, 5.57358265e-02, 2.05239177e-01,\n",
      "        0.00000000e+00, 2.42987704e+00, 0.00000000e+00, 1.88869524e+00,\n",
      "        9.57921028e+00, 1.29185438e+01, 5.54214239e-01, 0.00000000e+00,\n",
      "        0.00000000e+00, 1.13503051e+00, 1.59691438e-01, 0.00000000e+00,\n",
      "        1.65492153e+01, 1.01918347e-01, 1.23666763e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 1.59477444e+01, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        8.56922436e+00, 0.00000000e+00, 4.18778837e-01, 2.91453886e+00,\n",
      "        0.00000000e+00, 1.08113192e-01, 8.70395851e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 1.92704964e+00, 0.00000000e+00,\n",
      "        6.38081741e+00, 1.54897559e+00, 1.59493402e-01, 5.70290208e-01,\n",
      "        9.50055473e-05, 1.23664913e+01, 2.37396932e+00, 1.17745996e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 3.48372459e-02, 3.04679465e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.93241739e+00,\n",
      "        5.10351121e-01, 1.73393369e-01, 0.00000000e+00, 2.65145469e-02,\n",
      "        2.27526560e-01, 4.85876608e+00, 0.00000000e+00, 1.48827219e+00,\n",
      "        6.76508713e+00, 1.34510922e+00, 2.70934403e-01, 3.96931946e-01,\n",
      "        0.00000000e+00, 1.19611907e+00, 1.14920700e+00, 1.76127180e-01,\n",
      "        0.00000000e+00, 1.03140064e-01, 6.23394489e-01, 0.00000000e+00,\n",
      "        9.61219978e+00, 2.41579700e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        1.56067610e+00, 0.00000000e+00, 1.71919870e+00, 3.36959839e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.28348541e+00,\n",
      "        0.00000000e+00, 2.62869692e+00, 0.00000000e+00, 1.27955563e-02,\n",
      "        0.00000000e+00, 1.55053794e-01, 0.00000000e+00, 7.17902184e-01,\n",
      "        1.17616586e-01, 0.00000000e+00, 1.83896887e+00, 0.00000000e+00,\n",
      "        4.96638536e-01, 3.25596064e-01, 0.00000000e+00, 1.77260625e+00,\n",
      "        0.00000000e+00, 7.66492510e+00, 3.16762199e+01, 2.45312905e+00,\n",
      "        6.57384455e-01, 0.00000000e+00, 0.00000000e+00, 1.12234993e+01,\n",
      "        8.70620060e+00, 8.35999012e-01, 0.00000000e+00, 1.05660915e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.48935150e-02,\n",
      "        0.00000000e+00, 0.00000000e+00, 2.01859519e-01, 0.00000000e+00,\n",
      "        0.00000000e+00, 1.24926186e+00, 6.79782867e-01, 1.78154397e+00,\n",
      "        9.09697950e-01, 0.00000000e+00, 5.91877222e-01, 0.00000000e+00,\n",
      "        0.00000000e+00, 4.27158736e-03, 3.87816858e+00, 6.21340796e-02,\n",
      "        1.26266110e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.45219135e+00,\n",
      "        0.00000000e+00, 1.51503265e-01, 0.00000000e+00, 0.00000000e+00,\n",
      "        2.19172742e-02, 5.68689406e-02, 0.00000000e+00, 1.86683148e-01,\n",
      "        8.34818557e-02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        8.54679298e+00, 0.00000000e+00, 1.32964122e+00, 0.00000000e+00,\n",
      "        2.05904460e+00, 2.36913776e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        8.99367630e-02, 3.12560499e-01, 7.61422396e-01, 2.55142665e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 3.91490579e-01,\n",
      "        2.41318531e+01, 6.21230938e-02, 2.28808689e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.18884830e+01,\n",
      "        1.07020807e+01, 0.00000000e+00, 3.61538291e+00, 0.00000000e+00,\n",
      "        4.60133329e-03, 2.46996194e-01, 0.00000000e+00, 2.01926790e-02,\n",
      "        0.00000000e+00, 1.07281828e+00, 0.00000000e+00, 5.21178603e-01,\n",
      "        7.50797987e-01, 1.21596169e+00, 0.00000000e+00, 7.31118393e+00,\n",
      "        1.08903058e-01, 1.56530052e-01, 1.35819447e+00, 0.00000000e+00,\n",
      "        8.74905944e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 7.24375963e-01,\n",
      "        1.51332155e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 6.24834013e+00, 0.00000000e+00, 9.50822353e-01,\n",
      "        0.00000000e+00, 0.00000000e+00, 1.34574950e+00, 9.40605551e-02,\n",
      "        3.03629255e+00, 5.51609278e-01, 1.07149944e+01, 0.00000000e+00,\n",
      "        0.00000000e+00, 1.31462467e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        2.06429124e-01, 0.00000000e+00, 1.66191041e+00, 0.00000000e+00,\n",
      "        5.14737487e-01, 2.45709959e-02, 2.92262882e-01, 0.00000000e+00,\n",
      "        2.65379399e-02, 0.00000000e+00, 1.46240559e+01, 1.84139684e-01,\n",
      "        0.00000000e+00, 1.67950726e+00, 0.00000000e+00, 3.89493071e-02,\n",
      "        0.00000000e+00, 0.00000000e+00, 2.26942375e-01, 1.10972834e+01,\n",
      "        0.00000000e+00, 3.58915114e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        1.66407657e+00, 0.00000000e+00, 1.62286301e+01, 7.27726984e+00,\n",
      "        0.00000000e+00, 1.72896442e+01, 0.00000000e+00, 2.16657817e-01,\n",
      "        3.28932261e+00, 1.30528736e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        8.92780399e+00, 2.02188420e+00, 0.00000000e+00, 9.29590642e-01,\n",
      "        0.00000000e+00, 6.48592472e-01, 1.39104724e-01, 1.65890849e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        7.61247456e-01, 7.80278862e-01, 0.00000000e+00, 7.69136101e-03,\n",
      "        4.33052778e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        5.34584880e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        3.04249883e-01, 0.00000000e+00, 4.33624029e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 2.32694983e+00, 2.17576846e-02, 1.53275740e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 3.60740632e-01, 0.00000000e+00,\n",
      "        0.00000000e+00, 6.46816432e-01, 0.00000000e+00, 1.83274019e+00,\n",
      "        1.82847476e+00, 0.00000000e+00, 4.60027158e-01, 2.69407177e+00,\n",
      "        1.44373208e-01, 2.39256531e-01, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 3.21796596e-01, 4.21093273e+00,\n",
      "        4.36652839e-01, 0.00000000e+00, 0.00000000e+00, 4.75754529e-01,\n",
      "        1.25000751e+00, 0.00000000e+00, 2.06960320e-01, 0.00000000e+00,\n",
      "        0.00000000e+00, 7.63870031e-02, 0.00000000e+00, 0.00000000e+00,\n",
      "        2.17153445e-01, 0.00000000e+00, 8.29838037e-01, 1.72559750e+00,\n",
      "        3.49178648e+00, 0.00000000e+00, 0.00000000e+00, 6.31222844e-01,\n",
      "        0.00000000e+00, 0.00000000e+00, 1.18026745e+00, 2.93062806e-01,\n",
      "        7.37708747e-01, 0.00000000e+00, 0.00000000e+00, 1.21460535e-01,\n",
      "        0.00000000e+00, 0.00000000e+00, 3.22267652e+00, 2.98821616e+00,\n",
      "        6.51405811e+00, 0.00000000e+00, 0.00000000e+00, 5.87706089e-01,\n",
      "        0.00000000e+00, 1.17632282e+00, 2.39355946e+00, 0.00000000e+00,\n",
      "        1.23389232e+00, 1.38029262e-01, 0.00000000e+00, 0.00000000e+00,\n",
      "        4.87261105e+00, 0.00000000e+00, 1.50159347e+00, 2.20691609e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 5.45685291e-01,\n",
      "        0.00000000e+00, 1.01681717e-01, 9.12906468e-01, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 2.45644495e-01, 1.38195267e+01,\n",
      "        0.00000000e+00, 0.00000000e+00, 2.50442100e+00, 3.78372192e+00,\n",
      "        3.86931896e+00, 2.18424752e-01, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 7.07867265e-01,\n",
      "        1.68378592e-01, 4.07417677e-02, 0.00000000e+00, 0.00000000e+00,\n",
      "        1.52343054e+01, 1.86274350e+00, 3.60217404e+00, 0.00000000e+00,\n",
      "        2.70502734e+00, 2.65767717e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        1.81285131e+00, 0.00000000e+00, 0.00000000e+00, 1.13464959e-01,\n",
      "        0.00000000e+00, 0.00000000e+00, 9.07930955e-02, 0.00000000e+00,\n",
      "        1.16557426e+01, 0.00000000e+00, 1.54421991e-02, 0.00000000e+00,\n",
      "        4.35413456e+00, 1.84902176e-01, 5.73329568e-01, 4.85854805e-01,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 3.07802105e+00, 0.00000000e+00, 1.98535681e-01,\n",
      "        0.00000000e+00, 5.21680021e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 1.87071245e-02, 1.93921655e-01, 1.78612268e+00,\n",
      "        0.00000000e+00, 1.26392899e+01, 1.69336021e+00, 2.92576599e+00,\n",
      "        1.27826238e+00, 2.44746008e-03, 1.16489880e-01, 0.00000000e+00,\n",
      "        0.00000000e+00, 6.13486290e-01, 2.46636033e+00, 1.74433351e+00,\n",
      "        0.00000000e+00, 4.08141088e+00, 0.00000000e+00, 6.62621558e-02,\n",
      "        0.00000000e+00, 2.70001626e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.98278201e-01,\n",
      "        0.00000000e+00, 3.35861397e+00, 0.00000000e+00, 2.02863067e-01,\n",
      "        5.75287081e-02, 4.07756686e-01, 1.43791163e+00, 9.69321918e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 9.26321888e+00, 1.57009995e+00,\n",
      "        0.00000000e+00, 1.00088673e+01, 0.00000000e+00, 0.00000000e+00,\n",
      "        6.64799195e-03, 2.97440624e+00, 2.87188411e-01, 0.00000000e+00,\n",
      "        6.55559957e-01, 0.00000000e+00, 6.62394953e+00, 0.00000000e+00,\n",
      "        6.34887266e+00, 0.00000000e+00, 6.40100777e-01, 4.29558426e-01,\n",
      "        6.62281513e+00, 2.28078917e-01, 0.00000000e+00, 0.00000000e+00,\n",
      "        6.65286258e-02, 0.00000000e+00, 1.17034006e+00, 6.93517387e-01],\n",
      "       dtype=float32)\n",
      " None None None None None]\n",
      "Shape of the array: (6,)\n",
      "Data type of the array: object\n"
     ]
    }
   ],
   "source": [
    "file_path = 'C:/Documents/Projects_IC/creativision_nyu/UrbanCreativision/evec_scan/instances/test1/img_evecs/vgg16.npy' \n",
    "data = np.load(file_path, allow_pickle=True)\n",
    "print(data)\n",
    "print(\"Shape of the array:\", data.shape)\n",
    "print(\"Data type of the array:\", data.dtype)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ICenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
